{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0cf037b-450a-4773-b199-5a01ded7c701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf4594e9-c9f3-4bb1-b87b-2e9d67a621fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0deb4825-d3a3-4391-b790-0c5578ee19ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0edf9db-c41c-4ea6-903f-a8884d5b364b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis', device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b164038-e9ab-4537-b64b-7ac7885053b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"./700077347251945472.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f6eec9c-0eb2-4c0f-824d-ab4891090da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(x):\n",
    "    try: \n",
    "        return classifier(x)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d33e13f6-62d0-4f62-a115-6782c364c905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 2/492466 [00:00<41:33:55,  3.29it/s]/opt/conda/lib/python3.7/site-packages/transformers/pipelines/base.py:1046: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  UserWarning,\n",
      " 43% 211986/492466 [24:19<32:43, 142.83it/s] Token indices sequence length is longer than the specified maximum sequence length for this model (658 > 512). Running this sequence through the model will result in indexing errors\n",
      " 64% 314488/492466 [36:01<19:46, 150.06it/s] IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 89% 435971/492466 [49:49<06:30, 144.66it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df[\"pipe_sentiment_analysis\"] = df.content.progress_apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e8b8531-7609-4f3c-b886-1062df4148e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('./700077347251945472_sentiment.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbf17956-fba4-4655-84bf-97fd4eee5459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91498504-bc1b-4db4-824f-65b857bd4869",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100% 899k/899k [00:00<00:00, 40.3MB/s]\n",
      "Downloading: 100% 456k/456k [00:00<00:00, 35.7MB/s]\n",
      "Downloading: 100% 772/772 [00:00<00:00, 663kB/s]\n",
      "Downloading: 100% 1.16k/1.16k [00:00<00:00, 1.09MB/s]\n",
      "Downloading: 100% 782/782 [00:00<00:00, 696kB/s]\n",
      "Downloading: 100% 499M/499M [00:11<00:00, 43.9MB/s] \n"
     ]
    }
   ],
   "source": [
    "tokenizer_loaded = RobertaTokenizer.from_pretrained('zhayunduo/roberta-base-stocktwits-finetuned')\n",
    "model_loaded = RobertaForSequenceClassification.from_pretrained('zhayunduo/roberta-base-stocktwits-finetuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a32f0f4e-978a-42e6-b83f-23b5de2276ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocktwits = pipeline(\"text-classification\", model=model_loaded, tokenizer=tokenizer_loaded, device=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea0a5ddc-ce50-457f-943d-c0b12177b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_stocktwits(x):\n",
    "    try: \n",
    "        return stocktwits(x)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877a7f16-c32f-4c0d-8c77-3e41b2ce49a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "# the model was trained upon below preprocessing\n",
    "def process_text(texts):\n",
    "\n",
    "  # remove URLs\n",
    "  texts = re.sub(r'https?://\\S+', \"\", texts)\n",
    "  texts = re.sub(r'www.\\S+', \"\", texts)\n",
    "  # remove '\n",
    "  texts = texts.replace('&#39;', \"'\")\n",
    "  # remove symbol names\n",
    "  texts = re.sub(r'(\\#)(\\S+)', r'hashtag_\\2', texts)\n",
    "  texts = re.sub(r'(\\$)([A-Za-z]+)', r'cashtag_\\2', texts)\n",
    "  # remove usernames\n",
    "  texts = re.sub(r'(\\@)(\\S+)', r'mention_\\2', texts)\n",
    "  # demojize\n",
    "  texts = emoji.demojize(texts, delimiters=(\"\", \" \"))\n",
    "\n",
    "  return texts.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5053aa28-5020-4652-bde7-0653d791ef84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 8/492466 [00:00<1:50:10, 74.50it/s]/opt/conda/lib/python3.7/site-packages/transformers/pipelines/base.py:1046: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  UserWarning,\n",
      " 43% 211985/492466 [43:06<57:28, 81.34it/s]  Token indices sequence length is longer than the specified maximum sequence length for this model (744 > 512). Running this sequence through the model will result in indexing errors\n",
      " 87% 426717/492466 [1:26:53<13:06, 83.62it/s]"
     ]
    }
   ],
   "source": [
    "df[\"stocktwits\"] = df.content.progress_apply(get_sentiment_stocktwits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76c9118b-ba7f-45f7-8fa3-5bdf48164f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"./700077347251945472_sentiment.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55790a5b-5c74-4b97-b1ef-35409cf6c32d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
