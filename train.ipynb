{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49a339b5-8a04-4143-8f67-c63475062096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8cf600e-06e7-4a03-9c63-64d2406811f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"700077347251945472_label.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d398c55b-54e5-464f-a094-cd42bc800377",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"author\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "680a9713-1da0-43ca-a3f4-3c7149844b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"attachments\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3df4eb6d-6c69-47dc-a6c1-b3dc1a66e3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"embeds\", axis=1)\n",
    "df = df.drop(\"stickers\", axis=1)\n",
    "df = df.drop(\"reactions\", axis=1)\n",
    "df = df.drop(\"mentions\", axis=1)\n",
    "df = df.drop(\"ticker_len\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ca3961a-c313-44a0-ac29-a5293120ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"stocktwits_score\"] = df.stocktwits.apply(lambda x: 0 if x is None else (x[0]['score'] if x[0]['label'] == 'LABEL_1' else -x[0]['score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e659ed11-e66f-44f9-9b3b-0d5f8c02f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment_score\"] = df.pipe_sentiment_analysis.apply(lambda x: 0 if x is None else (x[0]['score'] if x[0]['label'] == 'POSITIVE' else -x[0]['score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "129ad4c5-1fe5-4c3b-afa7-7c551bc183bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"stocktwits\", axis=1)\n",
    "df = df.drop(\"pipe_sentiment_analysis\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "084bacd5-d91f-4fe3-af8a-5c9ed59146eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'count': 6, 'emoji': {'id': '', 'imageUrl': 'https://twemoji.maxcdn.com/v/latest/svg/1f440.svg', 'isAnimated': False, 'name': 'ðŸ‘€'}}]\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[492461].iloc[0].reactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1199a875-9354-44ff-bd87-8380518885df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7                                                      None\n",
       "10                                                     None\n",
       "10                                                     None\n",
       "22                                                     None\n",
       "167                                                    None\n",
       "                                ...                        \n",
       "492460                                                 None\n",
       "492460                                                 None\n",
       "492461    {'id': '', 'imageUrl': 'https://twemoji.maxcdn...\n",
       "492461    {'id': '', 'imageUrl': 'https://twemoji.maxcdn...\n",
       "492462    {'id': '', 'imageUrl': 'https://twemoji.maxcdn...\n",
       "Name: reactions, Length: 227233, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_reaction(x):\n",
    "    if len(x) == 0:\n",
    "        return\n",
    "    return [x[0]['emoji']\n",
    "df['reactions'].apply(process_reaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f2ef4e89-e03e-4b42-aa2a-f5b5ede827e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100% 968/968 [00:00<00:00, 619kB/s]\n",
      "Downloading: 100% 190/190 [00:00<00:00, 73.1kB/s]\n",
      "Downloading: 100% 3.79k/3.79k [00:00<00:00, 2.08MB/s]\n",
      "Downloading: 100% 645/645 [00:00<00:00, 281kB/s]\n",
      "Downloading: 100% 122/122 [00:00<00:00, 97.2kB/s]\n",
      "Downloading: 100% 471M/471M [00:09<00:00, 50.6MB/s] \n",
      "Downloading: 100% 53.0/53.0 [00:00<00:00, 41.6kB/s]\n",
      "Downloading: 100% 5.07M/5.07M [00:00<00:00, 44.1MB/s]\n",
      "Downloading: 100% 239/239 [00:00<00:00, 146kB/s]\n",
      "Downloading: 100% 9.08M/9.08M [00:00<00:00, 47.1MB/s]\n",
      "Downloading: 100% 480/480 [00:00<00:00, 273kB/s]\n",
      "Downloading: 100% 14.8M/14.8M [00:00<00:00, 49.0MB/s]\n",
      "Downloading: 100% 229/229 [00:00<00:00, 140kB/s]\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "embeddings = model.encode(list(df.content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "317cc8ae-ec8f-4c31-b1ae-3bfd84f1636f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['embeddings'] = embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b15c871-3710-407c-b335-d587d16f9d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"700077347251945472_embs.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1e861118-cc97-482b-ae4a-a813fb197540",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['stocktwits_score', 'sentiment_score'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28451/884445287.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'diretion_today'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stocktwits_score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sentiment_score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"diretion_today\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"timestamp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3462\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3464\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3466\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['stocktwits_score', 'sentiment_score'] not in index\""
     ]
    }
   ],
   "source": [
    "final = df[df['diretion_today'].notna()][[\"stocktwits_score\", \"sentiment_score\", \"diretion_today\", \"content\", \"timestamp\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e05b4b-82cf-4838-aa34-2d4556377a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset(final[:int(len(final) * 0.7)])\n",
    "test_data = TabularDataset(final[int(len(final) * 0.7):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ed9d535f-b2c3-4096-824e-1c404492504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_parquet(\"test_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a449f026-9592-4fa7-a823-dfec0bd90b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221124_080113/\"\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (153596 samples, 38.86 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221124_080113/\"\n",
      "AutoGluon Version:  0.6.0\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53-Ubuntu SMP Wed Sep 18 13:35:53 UTC 2019\n",
      "Train Data Rows:    153596\n",
      "Train Data Columns: 4\n",
      "Label Column: diretion_today\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [False, True]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = True, class 0 = False\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    470098.24 MB\n",
      "\tTrain Data (Original)  Memory Usage: 32.37 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['content']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 5302\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      : 2 | ['stocktwits_score', 'sentiment_score']\n",
      "\t\t('object', ['datetime_as_object']) : 1 | ['timestamp']\n",
      "\t\t('object', ['text'])               : 1 | ['content']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', ['text_as_category'])  :    1 | ['content']\n",
      "\t\t('float', [])                       :    2 | ['stocktwits_score', 'sentiment_score']\n",
      "\t\t('int', ['binned', 'text_special']) :   28 | ['content.char_count', 'content.word_count', 'content.capital_ratio', 'content.lower_ratio', 'content.digit_ratio', ...]\n",
      "\t\t('int', ['datetime_as_int'])        :    5 | ['timestamp', 'timestamp.year', 'timestamp.month', 'timestamp.day', 'timestamp.dayofweek']\n",
      "\t\t('int', ['text_ngram'])             : 5303 | ['__nlp__.00', '__nlp__.000', '__nlp__.00am', '__nlp__.01', '__nlp__.02', ...]\n",
      "\t50.8s = Fit runtime\n",
      "\t4 features in original data used to generate 5339 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1642.25 MB (0.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 64.89s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01627646553295659, Train Rows: 151095, Val Rows: 2501\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.6913\t = Validation score   (accuracy)\n",
      "\t18.0s\t = Training   runtime\n",
      "\t133.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.6813\t = Validation score   (accuracy)\n",
      "\t18.34s\t = Training   runtime\n",
      "\t126.05s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\tTraining LightGBMXT with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_error: 0.267093\n",
      "[2000]\tvalid_set's binary_error: 0.246701\n",
      "[3000]\tvalid_set's binary_error: 0.242703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.7613\t = Validation score   (accuracy)\n",
      "\t73.82s\t = Training   runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\tTraining LightGBM with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_error: 0.252299\n",
      "[2000]\tvalid_set's binary_error: 0.231108\n",
      "[3000]\tvalid_set's binary_error: 0.227909\n",
      "[4000]\tvalid_set's binary_error: 0.220312\n",
      "[5000]\tvalid_set's binary_error: 0.219112\n",
      "[6000]\tvalid_set's binary_error: 0.216713\n",
      "[7000]\tvalid_set's binary_error: 0.218713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.7853\t = Validation score   (accuracy)\n",
      "\t107.54s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.7073\t = Validation score   (accuracy)\n",
      "\t166.59s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.7177\t = Validation score   (accuracy)\n",
      "\t181.27s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tTraining CatBoost with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label='diretion_today').fit(train_data=train_data, num_gpus=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbe1a912-be43-4878-9b65-fdc2ecd8224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = TabularPredictor.load(\"AutogluonModels/ag-20221124_185158/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e8ff2cf-b927-4077-b92b-5753a25481b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_data[\"diretion_today\"]\n",
    "y_pred = predictor.predict(test_data.drop(columns=[\"diretion_today\"]))\n",
    "y_prob = predictor.predict_proba(test_data.drop(columns=[\"diretion_today\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fade17d1-7d21-4459-912b-da74f183f6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"y_pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d6a851ca-5f4c-4cae-85f8-a0bc1f707fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>376019</th>\n",
       "      <td>```fix\\nTop Trending: CEMI SOFI LEXX CCIV SQ N...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376019</th>\n",
       "      <td>```fix\\nTop Trending: CEMI SOFI LEXX CCIV SQ N...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376021</th>\n",
       "      <td>$NURO 5m</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376028</th>\n",
       "      <td>CEMI curling off the lower trendline (again)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376032</th>\n",
       "      <td>BTC ripping</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492460</th>\n",
       "      <td>```fix\\nTop Trending: LCID TOP ILAG TSLA NIO X...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492460</th>\n",
       "      <td>```fix\\nTop Trending: LCID TOP ILAG TSLA NIO X...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492460</th>\n",
       "      <td>```fix\\nTop Trending: LCID TOP ILAG TSLA NIO X...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492460</th>\n",
       "      <td>```fix\\nTop Trending: LCID TOP ILAG TSLA NIO X...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492460</th>\n",
       "      <td>```fix\\nTop Trending: LCID TOP ILAG TSLA NIO X...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65828 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  content  y_pred\n",
       "376019  ```fix\\nTop Trending: CEMI SOFI LEXX CCIV SQ N...    True\n",
       "376019  ```fix\\nTop Trending: CEMI SOFI LEXX CCIV SQ N...    True\n",
       "376021                                           $NURO 5m    True\n",
       "376028       CEMI curling off the lower trendline (again)    True\n",
       "376032                                        BTC ripping    True\n",
       "...                                                   ...     ...\n",
       "492460  ```fix\\nTop Trending: LCID TOP ILAG TSLA NIO X...    True\n",
       "492460  ```fix\\nTop Trending: LCID TOP ILAG TSLA NIO X...    True\n",
       "492460  ```fix\\nTop Trending: LCID TOP ILAG TSLA NIO X...    True\n",
       "492460  ```fix\\nTop Trending: LCID TOP ILAG TSLA NIO X...    True\n",
       "492460  ```fix\\nTop Trending: LCID TOP ILAG TSLA NIO X...    True\n",
       "\n",
       "[65828 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[[\"content\", \"y_pred\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf04b9e7-4383-4e25-a65a-4c6b1d6457b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12aa1de9-e448-4220-87c8-f3db727f5d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5688764659415446,\n",
       " 'balanced_accuracy': 0.5165564955032926,\n",
       " 'mcc': 0.05206957310818076,\n",
       " 'f1': 0.7039061847925883,\n",
       " 'precision': 0.5769158414994955,\n",
       " 'recall': 0.9025819397993311}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80be31fe-e427-4c5e-b0e8-9915874da0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autokeras as ak\n",
    "\n",
    "clf = ak.ImageClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "results = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be5f820-091e-4dae-9294-16ca80abbdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = df[df['diretion_today'].notna()][[\"stocktwits_score\", \"sentiment_score\", \"diretion_today\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
